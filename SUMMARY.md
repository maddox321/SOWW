# Summary

* [Wstęp](README.md)
* [Co oznaczają przedrostki](chapter1.md)
* [Paradygmaty programowania równoległego](paradygmaty_programowania_rownoleglego.md)
* [W jakim celu stosujemy równoległe przetwarzanie na klastrach?](w_jakim_celu_stosujemy_rownolegle_przetwarzanie_na_klastrach.md)
* [Zapisywanie i wznawianie stanu działania](zapisywanie_i_wznawianie_stanu_dzialania.md)
* [Prawo Amdahla](prawo_amdahla.md)
* [Prawo Gustafsona](prawo_gustafsona.md)
* [Metafora kierowcy](metafora_kierowcy.md)
* [MPI](mpi.md)
   * [Wyjaśnij jak zaimplementować w kodzie procesu (C+MPI) odbieranie dowolnych wiadomości od procesów o rankach 2,3 i 8.](wyjasnij_jak_zaimplementowac_w_kodzie_procesu_c+mpi_odbieranie_dowolnych_wiadomosci_od_procesow_o_rankach_2,3_i_8.md)
   * [Wyjaśnij jak zaimplementować barierę pomiędzy procesami w MPI_COMM_WORLD za pomocą funkcji MPI_SEND oraz MPI_RECV.](wyjasnij_jak_zaimplementowac_bariere_pomiedzy_procesami_w_mpicommworld_za_pomoc_a_funkcji_mpi_send_oraz_mpi_recv.md)
   * [MPI odebranie komunikatu o nieznanym rozmiarze](mpi_odebranie_komunikatu_o_nieznanym_rozmiarze.md)
   * [MPI_INIT_THREAD](mpiinit_thread.md)
   * [MPI_IRECV](mpiirecv.md)
   * [Napisz kod OpenMP + MPI - suma 1/(1+1) + 1(2+2) + ...](napisz_kod_openmp_+_mpi_-_suma_11+1_+_12+2_+.md)
   * [Jak się komunikować z procesem stworzonym przez MPI_COMM_SPAWN](jak_sie_komunikowac_z_procesem_stworzonym_przez_mpicommspawn.md)
   * [Typy funkcji send w MPI](typy_funkcji_send_w_mpi.md)
   * [Nakładanie komunikacji z obliczeniami + przykład + pseudokod przykładu (MPI+C)](nakladanie_komunikacji_z_obliczeniami_+_przyklad_+_pseudokod_przykladu_mpi+c.md)
* [Związek pomiędzy liczbą procesorów a speedupem](zwiazek_pomiedzy_liczba_procesorow_a_speedupem.md)
* [Kiedy przyśpieszenie ponad liniowe/ super liniowe?](kiedy_przyspieszenie_ponad_liniowe_super_liniowe.md)
* [Parametry wydajnościowe w komunikacje klastrów](parametry_wydajnosciowe_w_komunikacje_klastrow.md)

